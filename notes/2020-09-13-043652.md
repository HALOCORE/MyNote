# NLP

> NLP / Transformer

Attention is All you need

https://www.youtube.com/watch?v=iDulhoQ2pro&ab_channel=YannicKilcher

Bert

https://www.youtube.com/watch?v=OR0wfP2FD3c&ab_channel=HenryAILabs

LSTM is dead. Long Live Transformers

https://www.youtube.com/watch?v=S27pHKBEp30

## Attention is All you need

## LSTM is dead. Long Live Transformers

![image-20200913200309536](2020-09-13-043652.assets/image-20200913200309536.png)

- https://github.com/huggingface/transformers
  - both PyTorch and TensorFlow
  - Pre-trained models
  - Easy to fine-tune

![image-20200913201019001](2020-09-13-043652.assets/image-20200913201019001.png)

References
LSTM paper (scanned from stone tablets): https://www.bioinf.jku.at/publications/older/2604.pdf
LSTM diagrams, and a great deep dive: https://colah.github.io/posts/2015-08-Understanding-LSTMs/
Attention is all you need: https://arxiv.org/abs/1706.03762
Attention illustrated: https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3
BERT: https://arxiv.org/abs/1810.04805
ELMo: https://arxiv.org/pdf/1802.05365.pdf
Pre-trained transformer library: https://github.com/huggingface/transformers

## Illustrated Guide to Transformers Neural Network: A step by step explanation

https://www.youtube.com/watch?v=4Bdc55j80l8

![image-20200913204759293](2020-09-13-043652.assets/image-20200913204759293.png)